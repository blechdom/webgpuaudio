"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[852],{1696:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>h,default:()=>S,frontMatter:()=>l,metadata:()=>c,toc:()=>p});var a=n(5893),i=n(1151),s=n(7294),o=n(1229),r=n(1077),u=n(8281);class f{timeoutId=null;nextChunkOffset=0;workgroupSize=0;constructor(e){this.audioContext=new AudioContext,this.sampleRate=this.audioContext.sampleRate,this.chunkDurationInSeconds=e,this.chunkNumSamplesPerChannel=this.sampleRate*e,this.chunkNumSamples=2*this.chunkNumSamplesPerChannel,this.chunkBufferSize=this.chunkNumSamples*Float32Array.BYTES_PER_ELEMENT}async initGPU(e){let{code:t,entryPoint:n,workgroupSize:a}=e;this.workgroupSize=a;const i=await navigator.gpu.requestAdapter();this.device=await i.requestDevice(),this.timeInfoBuffer=this.device.createBuffer({size:Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),this.chunkBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),this.chunkMapBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST}),this.audioParamBuffer=this.device.createBuffer({size:15*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST}),this.audioShaderModule=this.device.createShaderModule({code:t}),this.pipeline=this.device.createComputePipeline({layout:"auto",compute:{module:this.audioShaderModule,entryPoint:n,constants:{SAMPLE_RATE:this.sampleRate,WORKGROUP_SIZE:a}}}),this.bindGroup=this.device.createBindGroup({layout:this.pipeline.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:this.timeInfoBuffer}},{binding:1,resource:{buffer:this.chunkBuffer}},{binding:2,resource:{buffer:this.audioParamBuffer}}]})}playSound(){(async()=>{await this.createSoundChunk()})()}async createSoundChunk(){if(!this.audioContext)return;void 0===this.startTime&&(this.startTime=performance.now()/1e3);const e=this.startTime+this.nextChunkOffset-performance.now()/1e3;if(Math.floor(e/this.chunkDurationInSeconds)>2){const e=this.chunkDurationInSeconds;return void(this.timeoutId=setTimeout(await this.createSoundChunk.bind(this),1e3*e))}this.device.queue.writeBuffer(this.timeInfoBuffer,0,new Float32Array([this.nextChunkOffset]));const t=this.device.createCommandEncoder(),n=t.beginComputePass();n.setPipeline(this.pipeline),n.setBindGroup(0,this.bindGroup),n.dispatchWorkgroups(Math.ceil(this.chunkNumSamplesPerChannel/this.workgroupSize)),n.end(),t.copyBufferToBuffer(this.chunkBuffer,0,this.chunkMapBuffer,0,this.chunkBufferSize),this.device.queue.submit([t.finish()]),await this.chunkMapBuffer.mapAsync(GPUMapMode.READ,0,this.chunkBufferSize);const a=new Float32Array(this.chunkNumSamples);a.set(new Float32Array(this.chunkMapBuffer.getMappedRange())),this.chunkMapBuffer.unmap();const i=this.audioContext.createBuffer(2,this.chunkNumSamplesPerChannel,this.audioContext.sampleRate),s=[];for(let r=0;r<2;++r)s.push(i.getChannelData(r));for(let r=0;r<i.length;++r)for(const[e,t]of s.entries())t[r]=a[2*r+e];const o=this.audioContext.createBufferSource();o.buffer=i,o.connect(this.audioContext.destination),0!==this.nextChunkOffset&&o.start(this.nextChunkOffset),this.nextChunkOffset+=o.buffer.duration,await this.createSoundChunk()}updateAudioParams(e){this.device.queue.writeBuffer(this.audioParamBuffer,0,new Float32Array(e))}async stop(){this.timeoutId&&clearTimeout(this.timeoutId),this.audioContext&&await this.audioContext.suspend(),this.audioContext&&await this.audioContext.close()}}const d="const PARTIALS: u32 = 256u;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\noverride WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\nstruct AudioParam {\n    partials: f32,\n    frequency: f32,\n    timeMod: f32,\n    timeScale: f32,\n    gain: f32,\n    dist: f32,\n    dur: f32,\n    ratio: f32,\n    sampOffset: f32,\n    fundamental: f32,\n    stereo: f32,\n    nse: f32,\n    res: f32,\n    lfo: f32,\n    flt: f32,\n}\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> song_chunk: array<vec2<f32>>; // 2 channel pcm data\n@binding(2) @group(0) var<storage, read> audio_param: AudioParam;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleCount: u32 = global_id.x;\n\n    if (sampleCount >= arrayLength(&song_chunk)) {\n        return;\n    }\n\n    let t = f32(sampleCount) / SAMPLE_RATE;\n\n    song_chunk[sampleCount] = mainSound(time_info.offset + t, audio_param);\n}\n\nfn dist(s: vec2<f32>, d: f32) -> vec2<f32> {\n    let distClamp: vec2<f32> = vec2(s * d);\n    let distSig: vec2<f32> = clamp(distClamp, vec2<f32>(-1.0), vec2<f32>(1.0));\n    return distSig;\n}\n\nfn _filter(h: f32, cut: f32, res: f32) -> f32 {\n\tlet cutted: f32 = cut - 20.0;\n\tlet df: f32 = max(h - cutted, 0.0);\n\tlet df2: f32 = abs(h - cutted);\n\treturn exp(-0.005 * df * df) * 0.5 + exp(df2 * df2 * -0.1) * res;\n}\n\nfn nse(x: f32) -> f32 {\n\treturn fract(sin(x * 110.082) * audio_param.nse);\n}\n\nfn ntof(n: f32, fundamental: f32) -> f32 {\n\treturn fundamental * pow(2.0, (n - 69.0) / 12.0);\n}\n\nfn synth(tseq: f32, t: f32, audio_param: AudioParam) -> vec2<f32> {\n    var v: vec2<f32> = vec2(0.0);\n    let tnote: f32 = fract(tseq);\n    let dr: f32 = audio_param.dur;\n    let amp: f32 = smoothstep(0.05, 0.0, abs(tnote - dr - 0.05) - dr) * exp(tnote * -1.0);\n    let seqn: f32 = nse(floor(tseq));\n    let n: f32 = 20.0 + floor(seqn * audio_param.frequency);\n    let f: f32 = ntof(n, audio_param.fundamental);\n    let sqr: f32 = smoothstep(0.0, 0.01, abs((t*audio_param.timeScale)%audio_param.timeMod - 20.0) - 20.0);\n    let base: f32 = f;\n    let flt: f32 = exp(tnote * audio_param.flt) * 50.0 + pow(cos(t * audio_param.lfo) * 0.5 + 0.5, 4.0) * 80.0;\n\n    for (var i = 0u; i < u32(audio_param.partials); i += 1) {\n        var h: f32 = f32(i + u32(audio_param.sampOffset));\n        var inten: f32 = 1.0 / h;\n\n        inten = mix(inten, inten * (h%audio_param.ratio), sqr);\n        inten *= exp(-1.0 * max(audio_param.ratio - h, 0.0));\n        inten *= _filter(h, flt, audio_param.res);\n\n        var vx = v.x + (inten * sin((PI2 + (audio_param.stereo / 2)) * (t * base * h)));\n        var vy = v.y + (inten * sin((PI2 - (audio_param.stereo / 2)) * (t * base * h)));\n        v = vec2(vx, vy);\n    }\n\n    let o: f32 = v.x * amp;\n\n    return vec2(dist(v * amp, audio_param.dist));\n}\n\nfn mainSound(time: f32, audio_param: AudioParam) -> vec2<f32> {\n\n    var tb: f32 = (time * audio_param.timeScale)%audio_param.timeMod;\n    var mx: vec2<f32> = synth(tb, time, audio_param) * audio_param.gain;\n\n  \treturn vec2(mx);\n}",l={title:"Acid Synth",sidebar_position:4},h=void 0,c={id:"wgslEditor/AcidSynth",title:"Acid Synth",description:"const [playing, setPlaying] = useState(false);",source:"@site/docs/wgslEditor/AcidSynth.mdx",sourceDirName:"wgslEditor",slug:"/wgslEditor/AcidSynth",permalink:"/webgpuaudio/docs/wgslEditor/AcidSynth",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Acid Synth",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"WGSL Audio Editor, One-Shots",permalink:"/webgpuaudio/docs/wgslEditor/WgslAudioOneShots"},next:{title:"Web Workers and ring buffers",permalink:"/webgpuaudio/docs/category/web-workers-and-ring-buffers"}},m={},p=[],g=function(){const e={li:"li",ul:"ul",...(0,i.a)()},t=[1,2,4,8,16,32,64,128,256],[n,l]=(0,s.useState)(!1),[h,c]=(0,s.useState)(),[m,p]=s.useState(d),[g,v]=(0,s.useState)(440);(0,s.useEffect)((()=>()=>{I()}),[]);const S=(0,s.useCallback)(((e,t)=>{console.log("val:",e),p(e)}),[]),{volume:x,partials:k,frequency:P,timeMod:b,timeScale:_,dist:w,dur:y,ratio:C,sampOffset:B,stereo:E,nse:A,res:M,lfo:U,flt:G,chunkDurationInSeconds:O,workgroupSize:R,loadShader:T}=(0,u.M4)({fundamental:{value:80,min:0,max:100,step:1e-4,onChange:e=>{const t=Math.log(1),n=(Math.log(1e3)-t)/100;v(Math.exp(t+n*(e-0)))}},string:{value:"Log of Fundamental",label:g.toFixed(3),editable:!1},frequency:{value:38,min:.2,max:100,step:.01},partials:{value:256,min:1,max:256,step:1},ratio:{value:2,min:1,max:32,step:.1},sampOffset:{value:1,min:1,max:32,step:1},dist:{value:.5,min:.01,max:5,step:.01},lfo:{value:1,min:0,max:64,step:.01},flt:{value:-1.5,min:-64,max:64,step:.01},res:{value:2.2,min:0,max:15,step:.01},dur:{value:.26,min:.001,max:2,step:.001},timeMod:{value:16,min:1,max:32,step:1},nse:{value:19871.8972,min:0,max:4e4,step:.001},stereo:{value:.01,min:-8,max:8,step:.001},timeScale:{value:9,min:.01,max:48,step:.01},volume:{value:.15,min:0,max:1,step:.01},WebGPUSettings:(0,u.so)({loadShader:{options:["acidSynth"]},chunkDurationInSeconds:{value:.1,min:.03,max:1,step:.01},workgroupSize:{options:t,value:t[8]}},{collapsed:!0}),[n?"Stop Sound":"Play Sound"]:(0,u.LI)((()=>{l(!n)}))},[n,g]);async function I(){h&&(await h.stop(),c(void 0))}return(0,s.useEffect)((()=>{n?async function(){if(void 0===h){const e=new f(O);await e.initGPU({code:m,entryPoint:"synthesize",workgroupSize:R}),c(e)}}():I()}),[n]),(0,s.useEffect)((()=>{n&&l(!1)}),[O,R,m]),(0,s.useEffect)((()=>{console.log("shader",T),p(d)}),[T]),(0,s.useEffect)((()=>{h&&h.playSound()}),[h]),(0,s.useEffect)((()=>{h&&h.updateAudioParams&&h.updateAudioParams(new Float32Array([k,P,b,_,x,w,y,C,B,g,E,A,M,U,G]))}),[h,g,x,k,P,b,_,x,w,y,C,B,E,A,M,U,G]),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(e.ul,{children:[(0,a.jsx)(e.li,{children:"Audio Synthesis uses rough streaming architecture to get chunks out of WebGPU and send control buffers to control a WebGPU compute shader."}),(0,a.jsx)(e.li,{children:"Select different shaders in the Leva control panel to hear different sounds."}),(0,a.jsx)(e.li,{children:"When changing WebGPU Parameters, the sound will stop and will need to be restarted."}),(0,a.jsx)(e.li,{children:"Changing sound parameters will happen at the rate of the chunk duration, so if you change the frequency, it will take a chunk duration to hear the change. (Interpolation options coming soon.)"}),(0,a.jsx)(e.li,{children:"Fully refresh the page if things get strange."}),(0,a.jsx)(e.li,{children:"The code below in the live wgsl editor creates the audio data in the WebGPU compute shader."})]}),(0,a.jsx)(u.Zf,{flat:!0,oneLineLabels:!0}),(0,a.jsx)(o.ZP,{value:m,width:"90%",height:"400px",extensions:[(0,r.i)()],onChange:S})]})};function v(e){return(0,a.jsx)(a.Fragment,{})}function S(e={}){return(0,a.jsx)(g,{...e,children:(0,a.jsx)(v,{...e})})}}}]);