"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[783],{3525:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>E,contentTitle:()=>S,default:()=>P,frontMatter:()=>A,metadata:()=>k,toc:()=>W});var i=n(5893),a=n(1151),s=n(1262),r=n(7294),o=n(2584),u=n(6998),l=n(6944),f=n(9639),c=n(9947),h=n(5095),d=n(1229),m=n(1077),g=n(8281),b=n(1750),p=n(9094);class v{timeoutId=null;constructor(e,t,i){this.code=i,this.workgroupSize=t,this.gpuWorker=new Worker(new URL(n.p+n.u(911),n.b),{type:void 0}),this.chunkDurationInSeconds=e,this.chunkNumSamplesPerChannel=this.sampleRate*e,this.init()}async init(){console.log("init"),this.audioContext=new AudioContext,this.sampleRate=this.audioContext.sampleRate,this.gpuWorker.addEventListener("message",(async e=>{if(console.log("chunkData in engine listener",e.data.chunkData),"chunk"===e.data.type)this.chunkData=e.data.chunkData})),this.inputQueue=await new b.Z(p.Nu,1),this.outputQueue=await new b.Z(p.Nu,1),this.atomicState=await new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT)),await this.audioContext.audioWorklet.addModule(new URL(n(8663),n.b));const e=new OscillatorNode(this.audioContext),t=new AudioWorkletNode(this.audioContext,"basic-processor",{processorOptions:{inputQueue:this.inputQueue,outputQueue:this.outputQueue,atomicState:this.atomicState}});e.connect(t).connect(this.audioContext.destination),e.start(),this.gpuWorker.postMessage({type:"init",data:{inputQueue:this.inputQueue,outputQueue:this.outputQueue,atomicState:this.atomicState}})}async stop(){this.audioContext&&(await this.audioContext.suspend(),await this.audioContext.close()),this.gpuWorker&&(await this.gpuWorker.terminate(),this.gpuWorker=void 0)}}function _(){const e=[1,2,4,8,16,32,64,128,256],[t,n]=r.useState(!1),[a,s]=r.useState(o.Z),[b,p]=r.useState(void 0);(0,r.useEffect)((()=>()=>{E()}),[]);const _=(0,r.useCallback)(((e,t)=>{console.log("val:",e),s(e)}),[]),{chunkDurationInSeconds:A,workgroupSize:S,loadShader:k}=(0,g.M4)({loadShader:{options:["sine","triangle","square","sawtooth","globalIdX","time"]},chunkDurationInSeconds:{value:2,min:.03,max:4,step:.01},workgroupSize:{options:e,value:e[8]},[t?"Stop Sound":"Play Sound"]:(0,g.LI)((()=>{n(!t)}))},[t]);async function E(){b&&(await b.stop(),p(void 0))}return(0,r.useEffect)((()=>{t?(console.log("playing"),async function(){void 0===b&&p(new v(A,S,a))}()):E()}),[t]),(0,r.useEffect)((()=>{t&&n(!1)}),[A,S,a]),(0,r.useEffect)((()=>{switch(console.log("shader",k),k){case"sine":default:s(o.Z);break;case"triangle":s(u.Z);break;case"square":s(l.Z);break;case"sawtooth":s(f.Z);break;case"globalIdX":s(c.Z);break;case"time":s(h.Z)}}),[k]),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)("ul",{children:[(0,i.jsx)("li",{children:"Audio Synthesis out of WebGPU, but this time in a WebWorker, and without streaming."}),(0,i.jsx)("li",{children:"Chunks of audio are generated in the Worker and then sent to the main thread to be process by the WebAudioAPI"}),(0,i.jsx)("li",{children:"Select different shaders in the Leva control panel to hear different sounds."}),(0,i.jsx)("li",{children:"When changing WebGPU Parameters, the sound will stop and will need to be restarted."}),(0,i.jsx)("li",{children:"Some of the sounds reveal the underlying architecture of the WebGPU shader, such a s the `globalIdX` and `time` shaders."}),(0,i.jsx)("li",{children:"Fully refresh the page if things get strange."}),(0,i.jsx)("li",{children:"The code below in the live wgsl editor creates the audio data in the WebGPU compute shader."})]}),(0,i.jsx)(g.Zf,{flat:!0,oneLineLabels:!0}),(0,i.jsx)(d.ZP,{value:a,width:"90%",height:"400px",extensions:[(0,m.i)()],onChange:_})]})}const A={title:"WebGPU Audio WebWorker Stream",sidebar_position:3},S=void 0,k={id:"webWorker/webGpuAudioWorkerStreaming",title:"WebGPU Audio WebWorker Stream",description:"",source:"@site/docs/webWorker/webGpuAudioWorkerStreaming.mdx",sourceDirName:"webWorker",slug:"/webWorker/webGpuAudioWorkerStreaming",permalink:"/docs/webWorker/webGpuAudioWorkerStreaming",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"WebGPU Audio WebWorker Stream",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Worklet/Worker Passthrough",permalink:"/docs/webWorker/workletWorkerFreeQueue"},next:{title:"WebAudio Oscillators",permalink:"/docs/webAudioOscillators"}},E={},W=[],w=function(){const e={div:"div",...(0,a.a)()};return(0,i.jsx)(s.Z,{fallback:(0,i.jsx)(e.div,{children:"Loading..."}),children:()=>(0,i.jsx)(_,{})})};function R(e){return(0,i.jsx)(i.Fragment,{})}function P(e={}){return(0,i.jsx)(w,{...e,children:(0,i.jsx)(R,{...e})})}},1262:(e,t,n)=>{n.d(t,{Z:()=>s});n(7294);var i=n(2389),a=n(5893);function s(e){let{children:t,fallback:n}=e;return(0,i.Z)()?(0,a.jsx)(a.Fragment,{children:t?.()}):n??null}},9094:(e,t,n)=>{n.d(t,{Nu:()=>i});const i=4096},1750:(e,t,n)=>{n.d(t,{Z:()=>a});class i{States={READ:0,WRITE:1};constructor(e,t){void 0===t&&(t=1),this.states=new Uint32Array(new SharedArrayBuffer(Object.keys(this.States).length*Uint32Array.BYTES_PER_ELEMENT)),this.bufferLength=e+1,this.channelCount=t,this.channelData=[];for(let n=0;n<t;n++)this.channelData.push(new Float32Array(new SharedArrayBuffer(this.bufferLength*Float32Array.BYTES_PER_ELEMENT)))}static fromPointers(e){const t=new i(0,0),n=new Uint32Array(e.memory.buffer),a=new Float32Array(e.memory.buffer),s=n[e.bufferLengthPointer/4],r=n[e.channelCountPointer/4],o=n.subarray(n[e.statePointer/4]/4,n[e.statePointer/4]/4+2),u=[];for(let i=0;i<r;i++)u.push(a.subarray(n[n[e.channelDataPointer/4]/4+i]/4,n[n[e.channelDataPointer/4]/4+i]/4+s));return t.bufferLength=s,t.channelCount=r,t.states=o,t.channelData=u,t}push(e,t){const n=Atomics.load(this.states,this.States.READ),i=Atomics.load(this.states,this.States.WRITE);if(this._getAvailableWrite(n,i)<t)return!1;let a=i+t;if(this.bufferLength<a){a-=this.bufferLength;for(let t=0;t<this.channelCount;t++){const n=this.channelData[t].subarray(i),s=this.channelData[t].subarray(0,a);n.set(e[t].subarray(0,n.length)),s.set(e[t].subarray(n.length))}}else{for(let n=0;n<this.channelCount;n++)this.channelData[n].subarray(i,a).set(e[n].subarray(0,t));a===this.bufferLength&&(a=0)}return Atomics.store(this.states,this.States.WRITE,a),!0}pull(e,t){const n=Atomics.load(this.states,this.States.READ),i=Atomics.load(this.states,this.States.WRITE);if(this._getAvailableRead(n,i)<t)return!1;let a=n+t;if(this.bufferLength<a){a-=this.bufferLength;for(let t=0;t<this.channelCount;t++){const i=this.channelData[t].subarray(n),s=this.channelData[t].subarray(0,a);e[t].set(i),e[t].set(s,i.length)}}else{for(let t=0;t<this.channelCount;++t)e[t].set(this.channelData[t].subarray(n,a));a===this.bufferLength&&(a=0)}return Atomics.store(this.states,this.States.READ,a),!0}printAvailableReadAndWrite(){const e=Atomics.load(this.states,this.States.READ),t=Atomics.load(this.states,this.States.WRITE);console.log(this,{availableRead:this._getAvailableRead(e,t),availableWrite:this._getAvailableWrite(e,t)})}getAvailableSamples(){const e=Atomics.load(this.states,this.States.READ),t=Atomics.load(this.states,this.States.WRITE);return this._getAvailableRead(e,t)}isFrameAvailable(e){return this.getAvailableSamples()>=e}getBufferLength(){return this.bufferLength-1}_getAvailableWrite(e,t){return t>=e?this.bufferLength-t+e-1:e-t-1}_getAvailableRead(e,t){return t>=e?t-e:t+this.bufferLength-e}_reset(){for(let e=0;e<this.channelCount;e++)this.channelData[e].fill(0);Atomics.store(this.states,this.States.READ,0),Atomics.store(this.states,this.States.WRITE,0)}}const a=i},9947:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, f32(global_id.x));\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},9639:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = 1.0 - 2.0*fract(time * freq);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},2584:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6944:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = square(time_info.offset + t);\n}\n\nfn square(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = step(fract(time * freq), 0.5) * 2.0 - 1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},5095:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, ((t - time_info.offset) * 400) + 200);\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6998:(e,t,n)=>{n.d(t,{Z:()=>i});const i="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = triangleWave(time_info.offset + t);\n}\n\nfn triangleWave(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = -abs(fract(time * freq)-0.5)*4.0-1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},8663:(e,t,n)=>{e.exports=n.p+"11ff4f83a261dfb3.js"}}]);