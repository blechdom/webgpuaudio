"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[689],{8554:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>g,contentTitle:()=>m,default:()=>E,frontMatter:()=>d,metadata:()=>p,toc:()=>_});var i=t(5893),o=t(7294),r=t(2308),s=t(1077),a=t(8281);class u{constructor(e,n,t,i,o,r,s,a){this.chunkDurationInSeconds=i,this.device=o,this.chunkNumSamplesPerChannel=n*i,this.chunkNumSamples=e*this.chunkNumSamplesPerChannel,this.chunkBufferSize=this.chunkNumSamples*Float32Array.BYTES_PER_ELEMENT,this.timeInfoBuffer=this.device.createBuffer({size:Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),this.chunkBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),this.chunkMapBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST}),this.audioShaderModule=o.createShaderModule({code:r}),this.pipeline=o.createComputePipeline({layout:"auto",compute:{module:this.audioShaderModule,entryPoint:s,constants:{SAMPLE_RATE:n,WORKGROUP_SIZE:t}}}),this.bindGroup=o.createBindGroup({layout:this.pipeline.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:this.timeInfoBuffer}},{binding:1,resource:{buffer:this.chunkBuffer}}]})}}var f=t(5475);const c="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}";var l=t(412);const d={title:"WGSL Audio Editor, no real-time inputs",sidebar_position:1},m=void 0,p={id:"wgslEditorExamples/WgslAudioNoInput",title:"WGSL Audio Editor, no real-time inputs",description:"const { device } = useDevice();",source:"@site/docs/wgslEditorExamples/WgslAudioNoInput.mdx",sourceDirName:"wgslEditorExamples",slug:"/wgslEditorExamples/WgslAudioNoInput",permalink:"/docs/wgslEditorExamples/WgslAudioNoInput",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"WGSL Audio Editor, no real-time inputs",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Audio Shaders: wgsl web editor",permalink:"/docs/category/audio-shaders-wgsl-web-editor"},next:{title:"WGSL Audio Editor, with real-time inputs",permalink:"/docs/wgslEditorExamples/WgslAudioEditorWithInputs"}},g={},_=[],h=function(){if(!l.Z.canUseDOM||"undefined"==typeof window)return;const e=[1,2,4,8,16,32,64,128,256],[n,t]=(0,o.useState)(void 0),[d,m]=(0,o.useState)(!1),[p,g]=(0,o.useState)(),[_,h]=(0,o.useState)(null),[v,E]=o.useState(c),{device:S}=(0,f.Z)(),b=(0,o.useCallback)(((e,n)=>{console.log("val:",e),E(e)}),[]),{chunkDurationInSeconds:k,workgroupSize:P,loadShader:R}=(0,a.M4)({loadShader:{options:["sine","triangle","square","sawtooth","globalIdX","time"]},chunkDurationInSeconds:{value:.15,min:.03,max:1,step:.01},workgroupSize:{options:e,value:e[8]},[d?"Stop Sound":"Play Sound"]:(0,a.LI)((()=>{m(!d)}),{order:-2})},[d]);return(0,o.useEffect)((()=>{d?t(new AudioContext):async function(){n&&await n.suspend();n&&await n.close();_&&clearTimeout(_);h(null),t(void 0),g(void 0)}()}),[d]),(0,o.useEffect)((()=>{d&&m(!1)}),[k,P,v]),(0,o.useEffect)((()=>{n&&(console.log("sample rate: ",n.sampleRate),async function(){void 0===p&&g(new u(2,n.sampleRate,P,k,S,v,"synthesize"))}())}),[n]),(0,o.useEffect)((()=>{switch(console.log("shader",R),R){case"sine":default:E(c);break;case"triangle":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = triangleWave(time_info.offset + t);\n}\n\nfn triangleWave(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = -abs(fract(time * freq)-0.5)*4.0-1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"square":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = square(time_info.offset + t);\n}\n\nfn square(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = step(fract(time * freq), 0.5) * 2.0 - 1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"sawtooth":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = 1.0 - 2.0*fract(time * freq);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"globalIdX":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, f32(global_id.x));\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"time":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, ((t - time_info.offset) * 400) + 200);\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}")}}),[R]),(0,o.useEffect)((()=>{p&&async function(){const e=performance.now()/1e3;let t=0;async function i(){if(!n||!d)return;const o=e+t-performance.now()/1e3;if(Math.floor(o/k)>2){return void h(setTimeout(i,1e3*(.9*k)))}S.queue.writeBuffer(p.timeInfoBuffer,0,new Float32Array([t]));const r=S.createCommandEncoder(),s=r.beginComputePass();s.setPipeline(p.pipeline),s.setBindGroup(0,p.bindGroup),s.dispatchWorkgroups(Math.ceil(p.chunkNumSamplesPerChannel/P)),s.end(),r.copyBufferToBuffer(p.chunkBuffer,0,p.chunkMapBuffer,0,p.chunkBufferSize),S.queue.submit([r.finish()]),await p.chunkMapBuffer.mapAsync(GPUMapMode.READ,0,p.chunkBufferSize);const a=new Float32Array(p.chunkNumSamples);a.set(new Float32Array(p.chunkMapBuffer.getMappedRange())),p.chunkMapBuffer.unmap();const u=n.createBuffer(2,p.chunkNumSamplesPerChannel,n.sampleRate),f=[];for(let e=0;e<2;++e)f.push(u.getChannelData(e));for(let e=0;e<u.length;++e)for(const[n,t]of f.entries())t[e]=a[2*e+n];const c=n.createBufferSource();c.buffer=u,c.connect(n.destination),c.start(t),t+=c.buffer.duration,d&&await i()}d&&i()}()}),[p]),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(a.Zf,{flat:!0,oneLineLabels:!0}),(0,i.jsx)(r.ZP,{value:v,width:"90%",height:"400px",extensions:[(0,s.i)()],onChange:b})]})};function v(e){return(0,i.jsx)(i.Fragment,{})}function E(e={}){return(0,i.jsx)(h,{...e,children:(0,i.jsx)(v,{...e})})}}}]);