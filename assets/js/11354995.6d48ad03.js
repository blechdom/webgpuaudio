"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[689],{8554:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>g,contentTitle:()=>p,default:()=>E,frontMatter:()=>d,metadata:()=>m,toc:()=>_});var t=i(5893),o=i(7294),r=i(2308),a=i(1077),s=i(8281);class u{constructor(e,n,i,t,o,r,a,s){this.chunkDurationInSeconds=t,this.device=o,this.chunkNumSamplesPerChannel=n*t,this.chunkNumSamples=e*this.chunkNumSamplesPerChannel,this.chunkBufferSize=this.chunkNumSamples*Float32Array.BYTES_PER_ELEMENT,this.timeInfoBuffer=this.device.createBuffer({size:Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),this.chunkBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),this.chunkMapBuffer=this.device.createBuffer({size:this.chunkBufferSize,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST}),this.audioShaderModule=o.createShaderModule({code:r}),this.pipeline=o.createComputePipeline({layout:"auto",compute:{module:this.audioShaderModule,entryPoint:a,constants:{SAMPLE_RATE:n,WORKGROUP_SIZE:i}}}),this.bindGroup=o.createBindGroup({layout:this.pipeline.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:this.timeInfoBuffer}},{binding:1,resource:{buffer:this.chunkBuffer}}]})}}var f=i(5475);const c="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}";var l=i(412);const d={title:"WGSL Audio Editor, no real-time inputs",sidebar_position:1},p=void 0,m={id:"wgslEditorExamples/WgslAudioNoInput",title:"WGSL Audio Editor, no real-time inputs",description:"const { device } = useDevice();",source:"@site/docs/wgslEditorExamples/WgslAudioNoInput.mdx",sourceDirName:"wgslEditorExamples",slug:"/wgslEditorExamples/WgslAudioNoInput",permalink:"/webgpuaudio/docs/wgslEditorExamples/WgslAudioNoInput",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"WGSL Audio Editor, no real-time inputs",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Audio Shaders: wgsl web editor",permalink:"/webgpuaudio/docs/category/audio-shaders-wgsl-web-editor"},next:{title:"WGSL Audio Editor, with real-time inputs",permalink:"/webgpuaudio/docs/wgslEditorExamples/WgslAudioEditorWithInputs"}},g={},_=[],h=function(){if(!l.Z.canUseDOM||"undefined"==typeof window)return;const e=[1,2,4,8,16,32,64,128,256],[n,i]=(0,o.useState)(void 0),[d,p]=(0,o.useState)(!1),[m,g]=(0,o.useState)(),[_,h]=(0,o.useState)(null),[v,E]=o.useState(c),{device:b}=(0,f.Z)(),S=(0,o.useCallback)(((e,n)=>{console.log("val:",e),E(e)}),[]),{chunkDurationInSeconds:k,workgroupSize:P,loadShader:w}=(0,s.M4)({loadShader:{options:["sine","triangle","square","sawtooth","globalIdX","time"]},chunkDurationInSeconds:{value:.15,min:.03,max:1,step:.01},workgroupSize:{options:e,value:e[8]},[d?"Stop Sound":"Play Sound"]:(0,s.LI)((()=>{p(!d)}),{order:-2})},[d]);return(0,o.useEffect)((()=>{d?i(new AudioContext):async function(){n&&await n.suspend();n&&await n.close();_&&clearTimeout(_);h(null),i(void 0),g(void 0)}()}),[d]),(0,o.useEffect)((()=>{d&&p(!1)}),[k,P,v]),(0,o.useEffect)((()=>{n&&(console.log("sample rate: ",n.sampleRate),async function(){void 0===m&&g(new u(2,n.sampleRate,P,k,b,v,"synthesize"))}())}),[n]),(0,o.useEffect)((()=>{switch(console.log("shader",w),w){case"sine":default:E(c);break;case"triangle":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = triangleWave(time_info.offset + t);\n}\n\nfn triangleWave(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = -abs(fract(time * freq)-0.5)*4.0-1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"square":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = square(time_info.offset + t);\n}\n\nfn square(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = step(fract(time * freq), 0.5) * 2.0 - 1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"sawtooth":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = 1.0 - 2.0*fract(time * freq);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"globalIdX":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, f32(global_id.x));\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}");break;case"time":E("override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, ((t - time_info.offset) * 400) + 200);\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}")}}),[w]),(0,o.useEffect)((()=>{m&&async function(){const e=performance.now()/1e3;let i=0;async function t(){if(!n||!d)return;const o=e+i-performance.now()/1e3;if(Math.floor(o/k)>2){return void h(setTimeout(t,1e3*(.9*k)))}b.queue.writeBuffer(m.timeInfoBuffer,0,new Float32Array([i]));const r=b.createCommandEncoder(),a=r.beginComputePass();a.setPipeline(m.pipeline),a.setBindGroup(0,m.bindGroup),a.dispatchWorkgroups(Math.ceil(m.chunkNumSamplesPerChannel/P)),a.end(),r.copyBufferToBuffer(m.chunkBuffer,0,m.chunkMapBuffer,0,m.chunkBufferSize),b.queue.submit([r.finish()]),await m.chunkMapBuffer.mapAsync(GPUMapMode.READ,0,m.chunkBufferSize);const s=new Float32Array(m.chunkNumSamples);s.set(new Float32Array(m.chunkMapBuffer.getMappedRange())),m.chunkMapBuffer.unmap();const u=n.createBuffer(2,m.chunkNumSamplesPerChannel,n.sampleRate),f=[];for(let e=0;e<2;++e)f.push(u.getChannelData(e));for(let e=0;e<u.length;++e)for(const[n,i]of f.entries())i[e]=s[2*e+n];const c=n.createBufferSource();c.buffer=u,c.connect(n.destination),c.start(i),i+=c.buffer.duration,d&&await t()}d&&t()}()}),[m]),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.Zf,{flat:!0,oneLineLabels:!0}),(0,t.jsx)(r.ZP,{value:v,width:"90%",height:"400px",extensions:[(0,a.i)()],onChange:S})]})};function v(e){return(0,t.jsx)(t.Fragment,{})}function E(e={}){return(0,t.jsx)(h,{...e,children:(0,t.jsx)(v,{...e})})}}}]);