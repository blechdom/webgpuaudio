"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[962],{8986:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>k,contentTitle:()=>b,default:()=>W,frontMatter:()=>v,metadata:()=>_,toc:()=>w});var o=t(5893),i=t(1151),r=t(7294);function s(){return new Worker(t.p+"assets/js/workerAudio.a04102dd.worker.js")}var a=t(2584),u=t(6998),f=t(6944),d=t(9639),l=t(9947),c=t(5095),m=t(1229),p=t(1077),h=t(8281);class g{timeoutId=null;constructor(e){this.audioContext=new AudioContext,this.sampleRate=this.audioContext.sampleRate,this.chunkDurationInSeconds=e,this.chunkNumSamplesPerChannel=this.sampleRate*e}async renderAudioChunk(e){if(!this.audioContext)return;const n=this.audioContext.createBuffer(2,this.chunkNumSamplesPerChannel,this.audioContext.sampleRate),t=[];for(let i=0;i<2;++i)t.push(n.getChannelData(i));for(let i=0;i<n.length;++i)for(const[n,o]of t.entries())o[i]=e[2*i+n];const o=this.audioContext.createBufferSource();o.buffer=n,o.connect(this.audioContext.destination),o.start(0)}async stop(){this.audioContext&&await this.audioContext.suspend(),this.audioContext&&await this.audioContext.close()}}const v={title:"WebGPU Audio WebWorker Example",sidebar_position:1},b=void 0,_={id:"webWorker/webGpuAudioWorker",title:"WebGPU Audio WebWorker Example",description:"useEffect(() => {",source:"@site/docs/webWorker/webGpuAudioWorker.mdx",sourceDirName:"webWorker",slug:"/webWorker/webGpuAudioWorker",permalink:"/docs/webWorker/webGpuAudioWorker",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"WebGPU Audio WebWorker Example",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Web Workers and ring buffers",permalink:"/docs/category/web-workers-and-ring-buffers"},next:{title:"WebAudio Oscillators",permalink:"/docs/webAudioOscillators"}},k={},w=[],E=function(){const e={li:"li",ul:"ul",...(0,i.a)()},n=[1,2,4,8,16,32,64,128,256],[t,v]=r.useState(!1),[b,_]=r.useState(a.Z),[k,w]=r.useState(void 0),[E,S]=r.useState(void 0),[W,P]=r.useState([]);(0,r.useEffect)((()=>()=>{y()}),[]);const R=(0,r.useCallback)(((e,n)=>{console.log("val:",e),_(e)}),[]),{chunkDurationInSeconds:x,workgroupSize:A,loadShader:I}=(0,h.M4)({loadShader:{options:["sine","triangle","square","sawtooth","globalIdX","time"]},chunkDurationInSeconds:{value:2,min:.03,max:4,step:.01},workgroupSize:{options:n,value:n[8]},[t?"Stop Sound":"Play Sound"]:(0,h.LI)((()=>{v(!t)}))},[t]);async function y(){k&&(await k.stop(),w(void 0)),E&&(E.terminate(),S(void 0))}return(0,r.useEffect)((()=>{t?(console.log("playing"),async function(){if(void 0===k){const e=new g(x);w(e)}}()):y()}),[t]),(0,r.useEffect)((()=>{if(k&&E){const n=k.sampleRate;try{E.postMessage({type:"run",chunkDurationInSeconds:x,code:b,workgroupSize:A,sampleRate:n})}catch(e){console.warn(e.message),E.terminate()}}}),[k,E,x,A,b]),(0,r.useEffect)((()=>{k&&E&&async function(){await k.renderAudioChunk(W)}()}),[W]),(0,r.useEffect)((()=>{t&&v(!1)}),[x,A,b]),(0,r.useEffect)((()=>{switch(console.log("shader",I),I){case"sine":default:_(a.Z);break;case"triangle":_(u.Z);break;case"square":_(f.Z);break;case"sawtooth":_(d.Z);break;case"globalIdX":_(l.Z);break;case"time":_(c.Z)}}),[I]),(0,r.useEffect)((()=>{k&&void 0===E&&async function(e){const n=new s({type:"module"});S(n),n.addEventListener("message",(async e=>{if("chunk"===e.data.type)P(e.data.chunkData)}))}()}),[k]),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(e.ul,{children:[(0,o.jsx)(e.li,{children:"Audio Synthesis out of WebGPU, but this time in a WebWorker, and without streaming."}),(0,o.jsx)(e.li,{children:"Chunks of audio are generated in the Worker and then sent to the main thread to be process by the WebAudioAPI"}),(0,o.jsx)(e.li,{children:"Select different shaders in the Leva control panel to hear different sounds."}),(0,o.jsx)(e.li,{children:"When changing WebGPU Parameters, the sound will stop and will need to be restarted."}),(0,o.jsx)(e.li,{children:"Some of the sounds reveal the underlying architecture of the WebGPU shader, such a s the `globalIdX` and `time` shaders."}),(0,o.jsx)(e.li,{children:"Fully refresh the page if things get strange."}),(0,o.jsx)(e.li,{children:"The code below in the live wgsl editor creates the audio data in the WebGPU compute shader."})]}),(0,o.jsx)(h.Zf,{flat:!0,oneLineLabels:!0}),(0,o.jsx)(m.ZP,{value:b,width:"90%",height:"400px",extensions:[(0,p.i)()],onChange:R})]})};function S(e){return(0,o.jsx)(o.Fragment,{})}function W(e={}){return(0,o.jsx)(E,{...e,children:(0,o.jsx)(S,{...e})})}},9947:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, f32(global_id.x));\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},9639:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = 1.0 - 2.0*fract(time * freq);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},2584:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6944:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = square(time_info.offset + t);\n}\n\nfn square(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = step(fract(time * freq), 0.5) * 2.0 - 1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},5095:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, ((t - time_info.offset) * 400) + 200);\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6998:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = triangleWave(time_info.offset + t);\n}\n\nfn triangleWave(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = -abs(fract(time * freq)-0.5)*4.0-1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"}}]);