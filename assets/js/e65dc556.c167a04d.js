"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[962],{1171:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>S,contentTitle:()=>k,default:()=>P,frontMatter:()=>_,metadata:()=>w,toc:()=>W});var o=t(5893),i=t(1151),r=t(1262);function s(){return new Worker(t.p+"assets/js/webGpuAudio.worker.a04102dd.worker.js")}var a=t(7294),u=t(2584),f=t(6998),d=t(6944),c=t(9639),l=t(9947),m=t(5095),h=t(1229),p=t(1077),g=t(8281);class v{timeoutId=null;constructor(e){this.audioContext=new AudioContext,this.sampleRate=this.audioContext.sampleRate,this.chunkDurationInSeconds=e,this.chunkNumSamplesPerChannel=this.sampleRate*e}async renderAudioChunk(e){if(!this.audioContext)return;const n=this.audioContext.createBuffer(2,this.chunkNumSamplesPerChannel,this.audioContext.sampleRate),t=[];for(let i=0;i<2;++i)t.push(n.getChannelData(i));for(let i=0;i<n.length;++i)for(const[n,o]of t.entries())o[i]=e[2*i+n];const o=this.audioContext.createBufferSource();o.buffer=n,o.connect(this.audioContext.destination),o.start(0)}async stop(){this.audioContext&&await this.audioContext.suspend(),this.audioContext&&await this.audioContext.close()}}function b(){const e=[1,2,4,8,16,32,64,128,256],[n,t]=a.useState(!1),[i,r]=a.useState(u.Z),[b,_]=a.useState(void 0),[k,w]=a.useState(void 0),[S,W]=a.useState([]);(0,a.useEffect)((()=>()=>{I()}),[]);const E=(0,a.useCallback)(((e,n)=>{console.log("val:",e),r(e)}),[]),{chunkDurationInSeconds:x,workgroupSize:P,loadShader:R}=(0,g.M4)({loadShader:{options:["sine","triangle","square","sawtooth","globalIdX","time"]},chunkDurationInSeconds:{value:2,min:.03,max:4,step:.01},workgroupSize:{options:e,value:e[8]},[n?"Stop Sound":"Play Sound"]:(0,g.LI)((()=>{t(!n)}))},[n]);async function I(){b&&(await b.stop(),_(void 0)),k&&(k.terminate(),w(void 0))}return(0,a.useEffect)((()=>{n?(console.log("playing"),async function(){if(void 0===b){const e=new v(x);_(e)}}()):I()}),[n]),(0,a.useEffect)((()=>{if(b&&k){const n=b.sampleRate;try{k.postMessage({type:"run",chunkDurationInSeconds:x,code:i,workgroupSize:P,sampleRate:n})}catch(e){console.warn(e.message),k.terminate()}}}),[b,k,x,P,i]),(0,a.useEffect)((()=>{b&&k&&async function(){await b.renderAudioChunk(S)}()}),[S]),(0,a.useEffect)((()=>{n&&t(!1)}),[x,P,i]),(0,a.useEffect)((()=>{switch(console.log("shader",R),R){case"sine":default:r(u.Z);break;case"triangle":r(f.Z);break;case"square":r(d.Z);break;case"sawtooth":r(c.Z);break;case"globalIdX":r(l.Z);break;case"time":r(m.Z)}}),[R]),(0,a.useEffect)((()=>{b&&void 0===k&&async function(e){const n=new s({type:"module"});w(n),n.addEventListener("message",(async e=>{if("chunk"===e.data.type)W(e.data.chunkData)}))}()}),[b]),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)("ul",{children:[(0,o.jsx)("li",{children:"Audio Synthesis out of WebGPU, but this time in a WebWorker, and without streaming."}),(0,o.jsx)("li",{children:"Chunks of audio are generated in the Worker and then sent to the main thread to be process by the WebAudioAPI"}),(0,o.jsx)("li",{children:"Select different shaders in the Leva control panel to hear different sounds."}),(0,o.jsx)("li",{children:"When changing WebGPU Parameters, the sound will stop and will need to be restarted."}),(0,o.jsx)("li",{children:"Some of the sounds reveal the underlying architecture of the WebGPU shader, such a s the `globalIdX` and `time` shaders."}),(0,o.jsx)("li",{children:"Fully refresh the page if things get strange."}),(0,o.jsx)("li",{children:"The code below in the live wgsl editor creates the audio data in the WebGPU compute shader."})]}),(0,o.jsx)(g.Zf,{flat:!0,oneLineLabels:!0}),(0,o.jsx)(h.ZP,{value:i,width:"90%",height:"400px",extensions:[(0,p.i)()],onChange:E})]})}const _={title:"WebGPU Audio WebWorker Example",sidebar_position:1},k=void 0,w={id:"webWorker/webGpuAudioWorker",title:"WebGPU Audio WebWorker Example",description:"",source:"@site/docs/webWorker/webGpuAudioWorker.mdx",sourceDirName:"webWorker",slug:"/webWorker/webGpuAudioWorker",permalink:"/docs/webWorker/webGpuAudioWorker",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"WebGPU Audio WebWorker Example",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Web Workers and ring buffers",permalink:"/docs/category/web-workers-and-ring-buffers"},next:{title:"Worklet/Worker Passthrough",permalink:"/docs/webWorker/workletWorkerFreeQueue"}},S={},W=[],E=function(){const e={div:"div",...(0,i.a)()};return(0,o.jsx)(r.Z,{fallback:(0,o.jsx)(e.div,{children:"Loading..."}),children:()=>(0,o.jsx)(b,{})})};function x(e){return(0,o.jsx)(o.Fragment,{})}function P(e={}){return(0,o.jsx)(E,{...e,children:(0,o.jsx)(x,{...e})})}},1262:(e,n,t)=>{t.d(n,{Z:()=>r});t(7294);var o=t(2389),i=t(5893);function r(e){let{children:n,fallback:t}=e;return(0,o.Z)()?(0,i.jsx)(i.Fragment,{children:n?.()}):t??null}},9947:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, f32(global_id.x));\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},9639:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute\n@workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = 1.0 - 2.0*fract(time * freq);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},2584:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t);\n}\n\nfn sine(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6944:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = square(time_info.offset + t);\n}\n\nfn square(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = step(fract(time * freq), 0.5) * 2.0 - 1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},5095:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\nconst PI2: f32 = 6.283185307179586476925286766559;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = sine(time_info.offset + t, ((t - time_info.offset) * 400) + 200);\n}\n\nfn sine(time: f32, freq: f32) -> vec2<f32> {\n    var v: f32 = sin(time * freq * PI2);\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"},6998:(e,n,t)=>{t.d(n,{Z:()=>o});const o="override WORKGROUP_SIZE: u32 = 256;\noverride SAMPLE_RATE: f32 = 44100.0;\n\nstruct TimeInfo { offset: f32 }\n\n@group(0) @binding(0) var<uniform> time_info: TimeInfo;\n@group(0) @binding(1) var<storage, read_write> sound_chunk: array<vec2<f32>>;\n\n@compute @workgroup_size(WORKGROUP_SIZE)\nfn synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\n    let sampleX = global_id.x;\n\n    let t = f32(sampleX) / SAMPLE_RATE;\n\n    sound_chunk[sampleX] = triangleWave(time_info.offset + t);\n}\n\nfn triangleWave(time: f32) -> vec2<f32> {\n    const freq: f32 = 333;\n    var v: f32 = -abs(fract(time * freq)-0.5)*4.0-1.0;\n    const amp: f32 = 0.25;\n    return vec2(v * amp);\n}"}}]);