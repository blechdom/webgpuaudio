"use strict";(self.webpackChunkwebgpuaudio=self.webpackChunkwebgpuaudio||[]).push([[550],{4781:(t,e,s)=>{s.r(e),s.d(e,{assets:()=>A,contentTitle:()=>W,default:()=>m,frontMatter:()=>f,metadata:()=>g,toc:()=>p});var a=s(5893),r=s(1151),i=s(5742),o=s(1262),n=s(7294),h=s(8281);class u{States={READ:0,WRITE:1};constructor(t,e){void 0===e&&(e=1),this.states=new Uint32Array(new SharedArrayBuffer(Object.keys(this.States).length*Uint32Array.BYTES_PER_ELEMENT)),this.bufferLength=t+1,this.channelCount=e,this.channelData=[];for(let s=0;s<e;s++)this.channelData.push(new Float32Array(new SharedArrayBuffer(this.bufferLength*Float32Array.BYTES_PER_ELEMENT)))}static fromPointers(t){const e=new u(0,0),s=new Uint32Array(t.memory.buffer),a=new Float32Array(t.memory.buffer),r=s[t.bufferLengthPointer/4],i=s[t.channelCountPointer/4],o=s.subarray(s[t.statePointer/4]/4,s[t.statePointer/4]/4+2),n=[];for(let h=0;h<i;h++)n.push(a.subarray(s[s[t.channelDataPointer/4]/4+h]/4,s[s[t.channelDataPointer/4]/4+h]/4+r));return e.bufferLength=r,e.channelCount=i,e.states=o,e.channelData=n,e}push(t,e){const s=Atomics.load(this.states,this.States.READ),a=Atomics.load(this.states,this.States.WRITE);if(this._getAvailableWrite(s,a)<e)return!1;let r=a+e;if(this.bufferLength<r){r-=this.bufferLength;for(let e=0;e<this.channelCount;e++){const s=this.channelData[e].subarray(a),i=this.channelData[e].subarray(0,r);s.set(t[e].subarray(0,s.length)),i.set(t[e].subarray(s.length))}}else{for(let s=0;s<this.channelCount;s++)this.channelData[s].subarray(a,r).set(t[s].subarray(0,e));r===this.bufferLength&&(r=0)}return Atomics.store(this.states,this.States.WRITE,r),!0}pull(t,e){const s=Atomics.load(this.states,this.States.READ),a=Atomics.load(this.states,this.States.WRITE);if(this._getAvailableRead(s,a)<e)return!1;let r=s+e;if(this.bufferLength<r){r-=this.bufferLength;for(let e=0;e<this.channelCount;e++){const a=this.channelData[e].subarray(s),i=this.channelData[e].subarray(0,r);t[e].set(a),t[e].set(i,a.length)}}else{for(let e=0;e<this.channelCount;++e)t[e].set(this.channelData[e].subarray(s,r));r===this.bufferLength&&(r=0)}return Atomics.store(this.states,this.States.READ,r),!0}printAvailableReadAndWrite(){const t=Atomics.load(this.states,this.States.READ),e=Atomics.load(this.states,this.States.WRITE);console.log(this,{availableRead:this._getAvailableRead(t,e),availableWrite:this._getAvailableWrite(t,e)})}getAvailableSamples(){const t=Atomics.load(this.states,this.States.READ),e=Atomics.load(this.states,this.States.WRITE);return this._getAvailableRead(t,e)}isFrameAvailable(t){return this.getAvailableSamples()>=t}getBufferLength(){return this.bufferLength-1}_getAvailableWrite(t,e){return e>=t?this.bufferLength-e+t-1:t-e-1}_getAvailableRead(t,e){return e>=t?e-t:e+this.bufferLength-t}_reset(){for(let t=0;t<this.channelCount;t++)this.channelData[t].fill(0);Atomics.store(this.states,this.States.READ,0),Atomics.store(this.states,this.States.WRITE,0)}}const l=u;var c=s(9094);class d{timeoutId=null;constructor(){this.passthroughWorker=new Worker(new URL(s.p+s.u(829),s.b),{type:void 0}),this.init()}async init(){this.audioContext=new AudioContext,this.sampleRate=this.audioContext.sampleRate,this.inputQueue=await new l(c.Nu,1),this.outputQueue=await new l(c.Nu,1),this.atomicState=await new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT)),await this.audioContext.audioWorklet.addModule(new URL(s(8663),s.b));const t=new OscillatorNode(this.audioContext),e={inputQueue:this.inputQueue,outputQueue:this.outputQueue,atomicState:this.atomicState},a=new AudioWorkletNode(this.audioContext,"basic-processor",{processorOptions:e});t.connect(a).connect(this.audioContext.destination),t.start(),this.passthroughWorker.postMessage({type:"init",data:e})}async stop(){this.audioContext&&(await this.audioContext.suspend(),await this.audioContext.close()),this.passthroughWorker&&(await this.passthroughWorker.terminate(),this.passthroughWorker=void 0)}}function b(){const[t,e]=n.useState(!1),[s,r]=n.useState(void 0);async function i(){s&&(await s.stop(),r(void 0))}return(0,n.useEffect)((()=>()=>{i()}),[]),(0,h.M4)({[t?"Stop Sound":"Play Sound"]:(0,h.LI)((()=>{e(!t)}))},[t]),(0,n.useEffect)((()=>{t?(console.log("playing"),async function(){void 0===s&&r(new d)}()):i()}),[t]),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)("ul",{children:[(0,a.jsx)("li",{children:"Web Audio is heard after passing through AudioWorklet and a WebWorker."}),(0,a.jsx)("li",{children:"Next, the audio will be passed from the WebWorker to WebGPU and back again, before returning to the AudioWorklet and then to WebAudio."})]}),(0,a.jsx)(h.Zf,{flat:!0,oneLineLabels:!0})]})}const f={title:"AudioWorklet WebWorker Passthrough",sidebar_position:2},W=void 0,g={id:"webWorker/workletWorkerPassthrough",title:"AudioWorklet WebWorker Passthrough",description:"",source:"@site/docs/webWorker/workletWorkerPassthrough.mdx",sourceDirName:"webWorker",slug:"/webWorker/workletWorkerPassthrough",permalink:"/docs/webWorker/workletWorkerPassthrough",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"AudioWorklet WebWorker Passthrough",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"WebGPU Audio WebWorker Example",permalink:"/docs/webWorker/webGpuAudioWorker"},next:{title:"AudioWorklet WebWorker WebGPU Passthrough",permalink:"/docs/webWorker/workletWorkerWebGpuPassthrough"}},A={},p=[],k=function(){const t={div:"div",...(0,r.a)()};return(0,a.jsx)(o.Z,{fallback:(0,a.jsx)(t.div,{children:"Loading..."}),children:()=>(0,a.jsx)(b,{})})};function w(t){return(0,a.jsx)(i.Z,{children:(0,a.jsx)("script",{src:"/scripts/coi-serviceworker.js"})})}function m(t={}){return(0,a.jsx)(k,{...t,children:(0,a.jsx)(w,{...t})})}},1262:(t,e,s)=>{s.d(e,{Z:()=>i});s(7294);var a=s(2389),r=s(5893);function i(t){let{children:e,fallback:s}=t;return(0,a.Z)()?(0,r.jsx)(r.Fragment,{children:e?.()}):s??null}},9094:(t,e,s)=>{s.d(e,{Nu:()=>a});const a=4096},8663:(t,e,s)=>{t.exports=s.p+"7a31eae271201b63.js"}}]);