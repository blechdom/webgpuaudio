---
title: WGSL Audio Editor, with real-time inputs
sidebar_position: 2
---

import React, { useEffect, useState, useCallback } from 'react';
import CodeMirror from '@uiw/react-codemirror';
import { wgsl } from "@iizukak/codemirror-lang-wgsl";
import { Leva, useControls, button, folder } from 'leva'
import WebGpuAudioEngine from '../../src/utils/WebGpuAudioEngine.ts';
import useDevice from '../../src/hooks/useDevice.ts';
import oscillatorsShader from '!!raw-loader!../../src/shaders/oscillators.wgsl';

export default function CodeMirrorWgsl() {
  const waveForms = ["sine", "triangle", "square", "sawtooth"];
  const shaders = ["oscillators"];
  const numChannels = 2;
  const workgroupSizes = [1, 2, 4, 8, 16, 32, 64, 128, 256];
  const maxBufferedChunks = 2;
  const [audioContext, setAudioContext] = useState(undefined);
  const [playing, setPlaying] = useState(false);
  const [engine, setEngine] = useState();
  const [timeoutId, setTimeoutId] = useState(null);
  const [freq, setFreq] = useState(440);
  const [code, setCode] = React.useState(oscillatorsShader);

  const { device } = useDevice();

  const onChange = useCallback((val, viewUpdate) => {
    console.log('val:', val);
    setCode(val);
  }, []);

  const { volume, waveForm, chunkDurationInSeconds, workgroupSize, loadShader } = useControls({
    waveForm: {options: waveForms},
    frequency: {
      value: 60,
      min: 0,
      max: 100,
      step: 0.0001,
      onChange: (v) => {
        const minIn = 0;
        const maxIn = 100;
        const minOut = Math.log(40);
        const maxOut = Math.log(3000);
        const scale = (maxOut - minOut) / (maxIn - minIn);
        setFreq(Math.exp(minOut + scale * (v - minIn)));
      },
    },
    string: {value: 'Hz', label: freq.toFixed(3), editable: false},
    volume: {
      value: 0.15,
      min: 0.0,
      max: 1.0,
      step: 0.01
    },
    WebGPUSettings: folder({
      loadShader: {options: shaders},
      chunkDurationInSeconds: {
        value: 0.15,
        min: 0.03,
        max: 1.0,
        step: 0.01
      },
      workgroupSize: {options: workgroupSizes, value: workgroupSizes[8]},
    }, {collapsed: true}),
    [playing ? "Stop Sound" : "Play Sound"]: button(() => {
      setPlaying(!playing)
    }, {order: -2}),
  }, [playing, freq]);

  useEffect(() => {
    if (playing) {
      setAudioContext(new AudioContext());
    } else {
      stopMakingSound();
    }

    async function stopMakingSound() {
      if (audioContext) await audioContext.suspend();
      if (audioContext) await audioContext.close();
      if (timeoutId) clearTimeout(timeoutId);
      setTimeoutId(null);
      setAudioContext(undefined);
      setEngine(undefined);
    }
  }, [playing]);

  useEffect(() => {
    if(playing) setPlaying(false);
  }, [chunkDurationInSeconds, workgroupSize, code])

  useEffect(() => {
    async function startMakingSound() {
      if (engine === undefined) {
        setEngine(new WebGpuAudioEngine(
          2,
          audioContext.sampleRate,
          workgroupSize,
          chunkDurationInSeconds,
          device,
          code,
          'synthesize',
          3,
        ));
      }
    }

    if (audioContext) {
      console.log("sample rate: ", audioContext.sampleRate);
      startMakingSound();
    }
  }, [audioContext]);

  useEffect(() => {
    console.log("shader", loadShader);
    switch(loadShader) {
      case "oscillators":
        setCode(oscillatorsShader);
        break;
      default:
        setCode(oscillatorsShader);
    }
  }, [loadShader]);

  useEffect(() => {
    if (engine) {
      playSound();
    }

    async function playSound() {
      const startTime = performance.now() / 1000.0;
      let nextChunkOffset = 0.0;

      async function createSongChunk() {
        if(!audioContext || !playing) return;
        const bufferedSeconds = (startTime + nextChunkOffset) - (performance.now() / 1000.0);
        const numBufferedChunks = Math.floor(bufferedSeconds / chunkDurationInSeconds);
        if (numBufferedChunks > maxBufferedChunks) {
          const timeout = chunkDurationInSeconds * 0.9;
          setTimeoutId(setTimeout(createSongChunk, timeout * 1000.0));
          return;
        }

        device.queue.writeBuffer(engine.timeInfoBuffer, 0, new Float32Array([nextChunkOffset]));

        const commandEncoder = device.createCommandEncoder();

        const pass = commandEncoder.beginComputePass();
        pass.setPipeline(engine.pipeline);
        pass.setBindGroup(0, engine.bindGroup);
        pass.dispatchWorkgroups(
          Math.ceil(engine.chunkNumSamplesPerChannel / workgroupSize)
        );
        pass.end();

        commandEncoder.copyBufferToBuffer(engine.chunkBuffer, 0, engine.chunkMapBuffer, 0, engine.chunkBufferSize);

        device.queue.submit([commandEncoder.finish()]);

        await engine.chunkMapBuffer.mapAsync(GPUMapMode.READ, 0, engine.chunkBufferSize);

        const chunkData = new Float32Array(engine.chunkNumSamples);
        chunkData.set(new Float32Array(engine.chunkMapBuffer.getMappedRange()));
        engine.chunkMapBuffer.unmap();

        const audioBuffer = audioContext.createBuffer(
          numChannels,
          engine.chunkNumSamplesPerChannel,
          audioContext.sampleRate
        );

        const channels = [];
        for (let i = 0; i < numChannels; ++i) {
          channels.push(audioBuffer.getChannelData(i));
        }

        for (let i = 0; i < audioBuffer.length; ++i) {
          for (const [offset, channel] of channels.entries()) {
            channel[i] = chunkData[i * numChannels + offset];
          }
        }

        const audioSource = audioContext.createBufferSource();
        audioSource.buffer = audioBuffer;
        audioSource.connect(audioContext.destination);

        audioSource.start(nextChunkOffset);

        nextChunkOffset += audioSource.buffer.duration;
        if (playing) await createSongChunk();
      }
      if (playing) createSongChunk();
    }
  }, [engine])


  useEffect(() => {
    if (!engine || !device) return;
    let waveFormNum = waveForms.indexOf(waveForm);
    device.queue.writeBuffer(engine.audioParamBuffer, 0, new Float32Array([freq, volume, waveFormNum]));
  }, [device, engine, freq, volume, waveForm]);


  return (
    <>
      <Leva flat oneLineLabels/>
      <CodeMirror value={code} width="90%" height="400px" extensions={[wgsl()]} onChange={onChange} />
    </>
  );
}